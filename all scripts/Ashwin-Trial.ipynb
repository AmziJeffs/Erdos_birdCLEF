{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience and saving\n",
    "ABRIDGED_RUN = False # Set to True to train and validate on 10% of the data, for quick funcitonality tests etc\n",
    "SAVE_AFTER_TRAINING = True # Save the model when you are done\n",
    "SAVE_CHECKPOINTS = True # Save the model after every epoch\n",
    "REPORT_TRAINING_LOSS_PER_EPOCH = True # Track the training loss each epoch, and write it to a file after training\n",
    "REPORT_VALIDATION_LOSS_PER_EPOCH = True # Lets us make a nice learning curve after training\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 256 # Number of samples per batch while training our network\n",
    "NUM_EPOCHS = 20 # Number of epochs to train our network\n",
    "LEARNING_RATE = 0.001 # Learning rate for our optimizer\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = \"../data/\"\n",
    "AUDIO_DIR = DATA_DIR + \"train_audio/\"\n",
    "AUDIO_DIR_DCASE = DATA_DIR + \"wav/\"\n",
    "AUDIO_DIR_2021 = DATA_DIR + \"train_soundscapes_2021/\"\n",
    "CHECKPOINT_DIR = \"checkpoints/\" # Checkpoints, models, and training data will be saved here\n",
    "MODEL_NAME = \"BIRDCALL_DETECTION_DCASE_ALL_DATA\"\n",
    "\n",
    "# Preprocessing info\n",
    "SAMPLE_RATE = 32000 # All our audio uses this sample rate\n",
    "SAMPLE_LENGTH = 5 # Duration we want to crop our audio to\n",
    "\n",
    "MIN_SAMPLE_LENGTH = 3.5 # Only use samples with length >= 3.5 seconds\n",
    "MAX_SAMPLE_LENGTH = 120 # Trim every sample to <= 120 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import librosa\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchaudio.transforms import MelSpectrogram, Resample\n",
    "from IPython.display import Audio\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCallDetector(nn.Module):\n",
    "    ''' Full architecture from https://github.com/musikalkemist/pytorchforaudio/blob/main/10%20Predictions%20with%20sound%20classifier/cnn.py'''\n",
    "    def __init__(self):\n",
    "        super(BirdCallDetector, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(10368, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/BIRDCALL_DETECTION_DCASE_ALL_DATA/final.pt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT_DIR + MODEL_NAME +'/final.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for training\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device} for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BirdCallDetector().to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_DIR + MODEL_NAME + '/final.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BirdCallDetector(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=10368, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms audio signal to a spectrogram\n",
    "spectrogram_transform = torchaudio.transforms.Spectrogram(\n",
    "        n_fft=2048,\n",
    "        win_length=2048,\n",
    "        hop_length=512,\n",
    "        power=2\n",
    "    )\n",
    "\n",
    "# Converts ordinary spectrogram to Mel scale\n",
    "mel_spectrogram_transform = torchaudio.transforms.MelScale(\n",
    "    n_mels=256,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    f_min=0,\n",
    "    f_max=16000,\n",
    "    n_stft=1025  # the number of frequency bins in the spectrogram\n",
    ")\n",
    "\n",
    "# Scales decibels to reasonable level (apply to a spectrogram or Mel spectrogram)\n",
    "db_scaler = torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80)\n",
    "\n",
    "# Resizes spectrograms into square images\n",
    "resize = transforms.Resize((224, 224), antialias = None)\n",
    "\n",
    "# Applies a frequency mask to a spectrogram\n",
    "def freq_mask(spec, F=30):\n",
    "    num_mel_channels = spec.shape[1]\n",
    "    f = random.randrange(0, F)\n",
    "    f_zero = random.randrange(0, num_mel_channels - f)\n",
    "    spec[:, f_zero:f_zero+f, :] = 0\n",
    "    return spec\n",
    "\n",
    "# Applies a time mask to a spectrogram\n",
    "def time_mask(spec, T=40):\n",
    "    spec_len = spec.shape[2]\n",
    "    t = random.randrange(0, T)\n",
    "    t_zero = random.randrange(0, spec_len - t)\n",
    "    spec[:, :, t_zero:t_zero+t] = 0\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices(seq, window_size = SAMPLE_RATE*SAMPLE_LENGTH, stride = None, align_left = True, return_scraps = True):\n",
    "    # If one window is larger than the sequence, just return the scraps or nothing\n",
    "    if window_size > seq.shape[0]:\n",
    "        if return_scraps == True:\n",
    "            return [seq]\n",
    "        else:\n",
    "            return []\n",
    "    # If stride is None, it defaults to window_size\n",
    "    if stride == None:\n",
    "        stride = window_size\n",
    "    index_slices = []\n",
    "    left_pointer = 0\n",
    "    while left_pointer + window_size <= seq.shape[0]:\n",
    "        index_slices += [[left_pointer, left_pointer + window_size]]\n",
    "        left_pointer += stride\n",
    "    if align_left == False:\n",
    "        offset = seq.shape[0]-(left_pointer-stride)-window_size\n",
    "        index_slices = [[a+offset, b+offset] for [a,b] in index_slices]\n",
    "    if return_scraps == True and left_pointer < seq.shape[0]:\n",
    "        if align_left == True:\n",
    "            index_slices += [[left_pointer, seq.shape[0]]]\n",
    "        else:\n",
    "            index_slices += [[0, seq.shape[0] - left_pointer]]\n",
    "    return [seq[a:b] for [a,b] in index_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCaseData(Dataset):\n",
    "    def __init__(self, signals, labels, training = True,\n",
    "        config = {'use_mel': True, 'time_mask': True, 'freq_mask': True}):\n",
    "        super().__init__()\n",
    "        self.training = training\n",
    "        self.config = config\n",
    "        print(f'Preprocessing {\"training\" if training else \"validation\"} data\\n')\n",
    "        self.processed_clips, self.labels = self.process(signals, labels)\n",
    "    def process(self, signals, labels):\n",
    "        results = []\n",
    "        new_labels = []\n",
    "        for i, signal in enumerate(signals):\n",
    "            # Uniformize to 5 seconds\n",
    "            if signal.shape[1] < SAMPLE_RATE * SAMPLE_LENGTH:\n",
    "                pad_length = SAMPLE_RATE * SAMPLE_LENGTH - signal.shape[1]\n",
    "                signal = torch.nn.functional.pad(signal, (0, pad_length))\n",
    "            # Cut signal into 5 second chunks to save\n",
    "            for clip in slices(signal.squeeze()):\n",
    "                results += [clip.unsqueeze(0)]\n",
    "                new_labels += [labels[i]]\n",
    "        return results, new_labels\n",
    "    def __len__(self):\n",
    "        return len(self.processed_clips)\n",
    "    def __getitem__(self, index):\n",
    "        # Process clip to tensor\n",
    "        x = self.processed_clips[index]\n",
    "        x = spectrogram_transform(x)\n",
    "        if self.config['use_mel']:\n",
    "            x = mel_spectrogram_transform(x)\n",
    "        x = db_scaler(x)\n",
    "        if self.config['time_mask'] and self.training:\n",
    "            x = time_mask(x)\n",
    "        if self.config['freq_mask'] and self.training:\n",
    "            x = freq_mask(x)\n",
    "        x = resize(x)\n",
    "        return x, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcase = pd.read_csv(DATA_DIR+'ff1010bird_metadata_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcase = dcase.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcase['filepath'] = AUDIO_DIR_DCASE + dcase['itemid'].astype(str)+'.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepath_to_signal(filepath):\n",
    "    sample, sr = torchaudio.load(filepath)\n",
    "    # Resampling to desired sample rate\n",
    "    sample = torchaudio.functional.resample(sample, orig_freq = sr, new_freq = SAMPLE_RATE)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcase['signal'] = dcase['filepath'].apply(filepath_to_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing validation data\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e8ecb8675c449ab04ab05c0e3989cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_dataset =  DCaseData(signals = dcase['signal'].to_list(), \n",
    "                                labels = dcase['hasbird'].to_list(),\n",
    "                                training = False)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "target = []\n",
    "for validation_data in validation_dataloader:\n",
    "            inputs, labels = validation_data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds += [output[1].item() for output in outputs]\n",
    "            target += [label.item() for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0013609020970761776, 0.0033772734459489584, 0.00048743459046818316, 0.0031949894037097692, 0.003915158100426197, 0.001928273937664926, 0.0002775616303551942, 0.00033905249438248575, 0.7415745854377747, 0.4081900715827942]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import BinaryAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = BinaryAUROC()\n",
    "metric.update(torch.tensor(preds), torch.tensor(target))\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsframe = pd.read_csv('/Users/ashwintan/Downloads/preds_birdCLEF2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsframe = predsframe.loc[:,['preds', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      preds  target\n",
       "0  0.045357       0\n",
       "1  0.002481       0\n",
       "2  0.004913       0\n",
       "3  0.002550       0\n",
       "4  0.000199       0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores = [None]*100\n",
    "thresholds = [0.01*i for i in range(100)]\n",
    "for i in range(100):\n",
    "    pred_labels = [0 if pred <= thresholds[i] else 1 for pred in predsframe['preds']]\n",
    "    target_labels = predsframe['target'].to_list()\n",
    "    acc_scores[i] = accuracy_score(target_labels, pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(thresholds, acc_scores)\n",
    "plt.ylabel('Accuracy score on BirdCLEF 2021 Dataset')\n",
    "plt.xlabel('Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36291666666666667, 0.7183333333333334, 0.76125, 0.7791666666666667, 0.7904166666666667, 0.7975, 0.8029166666666666, 0.8083333333333333, 0.8108333333333333, 0.81125, 0.8095833333333333, 0.8120833333333334, 0.8133333333333334, 0.8129166666666666, 0.8125, 0.8133333333333334, 0.81375, 0.815, 0.8154166666666667, 0.81625, 0.815, 0.81625, 0.8179166666666666, 0.81625, 0.8166666666666667, 0.8175, 0.8183333333333334, 0.8195833333333333, 0.81875, 0.8179166666666666, 0.8170833333333334, 0.8175, 0.81625, 0.8170833333333334, 0.8158333333333333, 0.8145833333333333, 0.8129166666666666, 0.8133333333333334, 0.8133333333333334, 0.8129166666666666, 0.8116666666666666, 0.8108333333333333, 0.8108333333333333, 0.8116666666666666, 0.8104166666666667, 0.8095833333333333, 0.80875, 0.8075, 0.8066666666666666, 0.8054166666666667, 0.8045833333333333, 0.8054166666666667, 0.8045833333333333, 0.8033333333333333, 0.8033333333333333, 0.8025, 0.8025, 0.8029166666666666, 0.8041666666666667, 0.8025, 0.8029166666666666, 0.8020833333333334, 0.8025, 0.8033333333333333, 0.8041666666666667, 0.80375, 0.8016666666666666, 0.8025, 0.8025, 0.8025, 0.8020833333333334, 0.8016666666666666, 0.79875, 0.7975, 0.7970833333333334, 0.79625, 0.7970833333333334, 0.7979166666666667, 0.79875, 0.7979166666666667, 0.7983333333333333, 0.7983333333333333, 0.7975, 0.7975, 0.79625, 0.79625, 0.7966666666666666, 0.79625, 0.7958333333333333, 0.7958333333333333, 0.7945833333333333, 0.7941666666666667, 0.7916666666666666, 0.7891666666666667, 0.7858333333333334, 0.785, 0.785, 0.7804166666666666, 0.7766666666666666, 0.7704166666666666]\n"
     ]
    }
   ],
   "source": [
    "print(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(range(100), key = acc_scores.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045833333333333"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195833333333333"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>39.2297</td>\n",
       "      <td>118.1987</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Matt Slaymaker</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.xeno-canto.org/134896</td>\n",
       "      <td>asbfly/XC134896.ogg</td>\n",
       "      <td>27.350219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>51.4030</td>\n",
       "      <td>104.6401</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Magnus Hellstrm</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>https://www.xeno-canto.org/164848</td>\n",
       "      <td>asbfly/XC164848.ogg</td>\n",
       "      <td>15.804094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>36.3319</td>\n",
       "      <td>127.3555</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Stuart Fisher</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>https://www.xeno-canto.org/175797</td>\n",
       "      <td>asbfly/XC175797.ogg</td>\n",
       "      <td>29.257156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>21.1697</td>\n",
       "      <td>70.6005</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>vir joshi</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/207738</td>\n",
       "      <td>asbfly/XC207738.ogg</td>\n",
       "      <td>14.158375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>15.5442</td>\n",
       "      <td>73.7733</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Albert Lastukhin &amp; Sergei Karpeev</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/209218</td>\n",
       "      <td>asbfly/XC209218.ogg</td>\n",
       "      <td>47.882438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 primary_label secondary_labels      type  latitude  longitude  \\\n",
       "0           0        asbfly               []  ['call']   39.2297   118.1987   \n",
       "1           1        asbfly               []  ['song']   51.4030   104.6401   \n",
       "2           2        asbfly               []  ['song']   36.3319   127.3555   \n",
       "3           3        asbfly               []  ['call']   21.1697    70.6005   \n",
       "4           4        asbfly               []  ['call']   15.5442    73.7733   \n",
       "\n",
       "      scientific_name             common_name  \\\n",
       "0  Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "1  Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "2  Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "3  Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "4  Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "\n",
       "                              author  \\\n",
       "0                     Matt Slaymaker   \n",
       "1                   Magnus Hellstrm   \n",
       "2                      Stuart Fisher   \n",
       "3                          vir joshi   \n",
       "4  Albert Lastukhin & Sergei Karpeev   \n",
       "\n",
       "                                             license  rating  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     5.0   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     2.5   \n",
       "2  Creative Commons Attribution-NonCommercial-Sha...     2.5   \n",
       "3  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "4  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "\n",
       "                                 url             filename   duration  \n",
       "0  https://www.xeno-canto.org/134896  asbfly/XC134896.ogg  27.350219  \n",
       "1  https://www.xeno-canto.org/164848  asbfly/XC164848.ogg  15.804094  \n",
       "2  https://www.xeno-canto.org/175797  asbfly/XC175797.ogg  29.257156  \n",
       "3  https://www.xeno-canto.org/207738  asbfly/XC207738.ogg  14.158375  \n",
       "4  https://www.xeno-canto.org/209218  asbfly/XC209218.ogg  47.882438  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR+\"full_metadata.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train_audio/asbfly/XC134896.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>27.350219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train_audio/asbfly/XC164848.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>15.804094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train_audio/asbfly/XC175797.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>29.257156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train_audio/asbfly/XC207738.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>14.158375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train_audio/asbfly/XC209218.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>47.882438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filepath primary_label   duration\n",
       "0  ../data/train_audio/asbfly/XC134896.ogg        asbfly  27.350219\n",
       "1  ../data/train_audio/asbfly/XC164848.ogg        asbfly  15.804094\n",
       "2  ../data/train_audio/asbfly/XC175797.ogg        asbfly  29.257156\n",
       "3  ../data/train_audio/asbfly/XC207738.ogg        asbfly  14.158375\n",
       "4  ../data/train_audio/asbfly/XC209218.ogg        asbfly  47.882438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['filepath'] = AUDIO_DIR + data['filename']\n",
    "data = data[['filepath', 'primary_label', 'duration']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['asbfly', 'ashdro1', 'ashpri1', 'ashwoo2', 'asikoe2', 'asiope1', 'aspfly1', 'aspswi1', 'barfly1', 'barswa', 'bcnher', 'bkcbul1', 'bkrfla1', 'bkskit1', 'bkwsti', 'bladro1', 'blaeag1', 'blakit1', 'blhori1', 'blnmon1', 'blrwar1', 'bncwoo3', 'brakit1', 'brasta1', 'brcful1', 'brfowl1', 'brnhao1', 'brnshr', 'brodro1', 'brwjac1', 'brwowl1', 'btbeat1', 'bwfshr1', 'categr', 'chbeat1', 'cohcuc1', 'comfla1', 'comgre', 'comior1', 'comkin1', 'commoo3', 'commyn', 'compea', 'comros', 'comsan', 'comtai1', 'copbar1', 'crbsun2', 'cregos1', 'crfbar1', 'crseag1', 'dafbab1', 'darter2', 'eaywag1', 'emedov2', 'eucdov', 'eurbla2', 'eurcoo', 'forwag1', 'gargan', 'gloibi', 'goflea1', 'graher1', 'grbeat1', 'grecou1', 'greegr', 'grefla1', 'grehor1', 'grejun2', 'grenig1', 'grewar3', 'grnsan', 'grnwar1', 'grtdro1', 'gryfra', 'grynig2', 'grywag', 'gybpri1', 'gyhcaf1', 'heswoo1', 'hoopoe', 'houcro1', 'houspa', 'inbrob1', 'indpit1', 'indrob1', 'indrol2', 'indtit1', 'ingori1', 'inpher1', 'insbab1', 'insowl1', 'integr', 'isbduc1', 'jerbus2', 'junbab2', 'junmyn1', 'junowl1', 'kenplo1', 'kerlau2', 'labcro1', 'laudov1', 'lblwar1', 'lesyel1', 'lewduc1', 'lirplo', 'litegr', 'litgre1', 'litspi1', 'litswi1', 'lobsun2', 'maghor2', 'malpar1', 'maltro1', 'malwoo1', 'marsan', 'mawthr1', 'moipig1', 'nilfly2', 'niwpig1', 'nutman', 'orihob2', 'oripip1', 'pabflo1', 'paisto1', 'piebus1', 'piekin1', 'placuc3', 'plaflo1', 'plapri1', 'plhpar1', 'pomgrp2', 'purher1', 'pursun3', 'pursun4', 'purswa3', 'putbab1', 'redspu1', 'rerswa1', 'revbul', 'rewbul', 'rewlap1', 'rocpig', 'rorpar', 'rossta2', 'rufbab3', 'ruftre2', 'rufwoo2', 'rutfly6', 'sbeowl1', 'scamin3', 'shikra1', 'smamin1', 'sohmyn1', 'spepic1', 'spodov', 'spoowl1', 'sqtbul1', 'stbkin1', 'sttwoo1', 'thbwar1', 'tibfly3', 'tilwar1', 'vefnut1', 'vehpar1', 'wbbfly1', 'wemhar1', 'whbbul2', 'whbsho3', 'whbtre1', 'whbwag1', 'whbwat1', 'whbwoo2', 'whcbar1', 'whiter2', 'whrmun', 'whtkin2', 'woosan', 'wynlau1', 'yebbab1', 'yebbul3', 'zitcis1']\n",
    "species_to_index = {species[i]:i for i in range(len(species))}\n",
    "data['index_label'] = data['primary_label'].apply(lambda x: species_to_index[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tensor_label'] = pd.Series(pd.get_dummies(data['primary_label']).astype(int).values.tolist()).apply(lambda x: torch.Tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>duration</th>\n",
       "      <th>index_label</th>\n",
       "      <th>tensor_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train_audio/asbfly/XC134896.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>27.350219</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(1.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train_audio/asbfly/XC164848.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>15.804094</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(1.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train_audio/asbfly/XC175797.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>29.257156</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(1.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train_audio/asbfly/XC207738.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>14.158375</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(1.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train_audio/asbfly/XC209218.ogg</td>\n",
       "      <td>asbfly</td>\n",
       "      <td>47.882438</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(1.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filepath primary_label   duration  \\\n",
       "0  ../data/train_audio/asbfly/XC134896.ogg        asbfly  27.350219   \n",
       "1  ../data/train_audio/asbfly/XC164848.ogg        asbfly  15.804094   \n",
       "2  ../data/train_audio/asbfly/XC175797.ogg        asbfly  29.257156   \n",
       "3  ../data/train_audio/asbfly/XC207738.ogg        asbfly  14.158375   \n",
       "4  ../data/train_audio/asbfly/XC209218.ogg        asbfly  47.882438   \n",
       "\n",
       "   index_label                                       tensor_label  \n",
       "0            0  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
       "1            0  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
       "2            0  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
       "3            0  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
       "4            0  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['duration'] >= MIN_SAMPLE_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>duration</th>\n",
       "      <th>index_label</th>\n",
       "      <th>tensor_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21105</th>\n",
       "      <td>../data/train_audio/rossta2/XC755715.ogg</td>\n",
       "      <td>rossta2</td>\n",
       "      <td>11.179094</td>\n",
       "      <td>144</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22995</th>\n",
       "      <td>../data/train_audio/whiter2/XC381842.ogg</td>\n",
       "      <td>whiter2</td>\n",
       "      <td>28.447344</td>\n",
       "      <td>174</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21544</th>\n",
       "      <td>../data/train_audio/spepic1/XC802723.ogg</td>\n",
       "      <td>spepic1</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>154</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>../data/train_audio/comsan/XC579400.ogg</td>\n",
       "      <td>comsan</td>\n",
       "      <td>5.093000</td>\n",
       "      <td>44</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>../data/train_audio/commoo3/XC618889.ogg</td>\n",
       "      <td>commoo3</td>\n",
       "      <td>14.158000</td>\n",
       "      <td>40</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filepath primary_label   duration  \\\n",
       "21105  ../data/train_audio/rossta2/XC755715.ogg       rossta2  11.179094   \n",
       "22995  ../data/train_audio/whiter2/XC381842.ogg       whiter2  28.447344   \n",
       "21544  ../data/train_audio/spepic1/XC802723.ogg       spepic1  59.640000   \n",
       "7508    ../data/train_audio/comsan/XC579400.ogg        comsan   5.093000   \n",
       "6269   ../data/train_audio/commoo3/XC618889.ogg       commoo3  14.158000   \n",
       "\n",
       "       index_label                                       tensor_label  \n",
       "21105          144  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "22995          174  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "21544          154  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "7508            44  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "6269            40  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[21105, 'tensor_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(182)\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCallDetector(nn.Module):\n",
    "    ''' Full architecture from https://github.com/musikalkemist/pytorchforaudio/blob/main/10%20Predictions%20with%20sound%20classifier/cnn.py'''\n",
    "    def __init__(self):\n",
    "        super(BirdCallDetector, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(10368, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepath_to_signal(filepath):\n",
    "    signal, _ = torchaudio.load(filepath)\n",
    "    if signal.shape[1] < SAMPLE_RATE * SAMPLE_LENGTH:\n",
    "        pad_length = SAMPLE_RATE * SAMPLE_LENGTH - signal.shape[1]\n",
    "        signal = torch.nn.functional.pad(signal, (0, pad_length))\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = filepath_to_signal(data.loc[21105, 'filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7997e-03, -5.9278e-03, -4.5872e-03,  ..., -1.6410e-05,\n",
       "         -1.1244e-05, -9.9803e-06]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pink_noise(samples):\n",
    "    b = [0.049922035, -0.095993537, 0.050612699, -0.004408786]\n",
    "    a = [1, -2.494956002, 2.017265875, -0.522189400]\n",
    "\n",
    "    pink_noise = np.random.randn(samples)\n",
    "    pink_noise = np.convolve(pink_noise, b)\n",
    "    pink_noise = np.convolve(pink_noise, a, mode='valid')\n",
    "    return torch.Tensor(pink_noise).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pink_noise(signal, snr):\n",
    "    pink = generate_pink_noise(signal.shape[1])\n",
    "    return torchaudio.functional.add_noise(signal, pink, torch.Tensor([snr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink = generate_pink_noise(signal.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 358592])\n"
     ]
    }
   ],
   "source": [
    "print(signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4159, -0.9910,  0.9693,  ..., -0.3631, -0.0884,  0.2061]])\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([1, 358592])\n"
     ]
    }
   ],
   "source": [
    "print(pink)\n",
    "print('\\n\\n')\n",
    "print(pink.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SNR = 20\n",
    "MIN_SNR = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0056, -0.0059, -0.0035,  ...,  0.0012, -0.0017,  0.0012]]) \n",
      " torch.Size([1, 358592])\n"
     ]
    }
   ],
   "source": [
    "x = add_pink_noise(signal, np.random.uniform(low = MIN_SNR, high = MAX_SNR))\n",
    "print(x, '\\n', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([358592])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_length = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal2 = torch.nn.functional.pad(signal.squeeze(), (0, pad_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0048, -0.0059, -0.0046,  ...,  0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0046, -0.0059, -0.0048])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(signal2, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = signal[:, :SAMPLE_RATE*SAMPLE_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spectrogram_transform(signal)\n",
    "x = mel_spectrogram_transform(x)\n",
    "x = db_scaler(x)\n",
    "x = resize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738466501235962"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.unsqueeze(0))[0][1].item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
